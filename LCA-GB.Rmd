---
title: "LCA-GB"
author: "Yi-Min Chang Chien"
date: "14/08/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(dplyr)
library(fasterize)
library(magrittr)
library(MASS)
library(raster)
library(sf)
library(tidyr)
library(xgboost)
library(yarrr)
# library(ggplot2)
# library(ggstance)
# library(GWmodel)
# library(kableExtra)
# library(knitr)
# library(openxlsx)
# library(tidyr)
```

```{r}
#### Data preparation
## Download the boundary of Wales
temp <- tempfile()
temp2 <- tempfile()
download.file("https://datashare.is.ed.ac.uk/bitstream/handle/10283/2410/Wales_boundary.zip", temp)
unzip(zipfile = temp, exdir = temp2)
"Wales boundary.shp" %>%
  file.path(temp2, .) %>%
  st_read(stringsAsFactors = FALSE) %>% 
  st_transform(crs = 27700) %>%
  st_combine() ->
  Wales
rm(list = c("temp", "temp2"))

load("/Users/Yi-Min/Rsession/ScenicOrNot/scenicness/Grid/Hexgonal Grid/5km.RData")
load("/Users/Yi-Min/Rsession/ScenicOrNot/scenicness/Grid/Hexgonal Grid/2km.RData")
st_crs(hex.5k) == st_crs(Wales) # checking the coordinate reference system
st_crs(hex.2k) == st_crs(Wales) # checking the coordinate reference system
hex.5km <- hex.5k[Wales, ]
hex.2km <- hex.2k[Wales, ]
```

# Data preparation/sampling

```{r}
# Rasterising LANDMAP data
VS <- read_sf("http://lle.gov.wales/catalogue/item/LandmapVisualSensory.json") %>%
  st_make_valid() %>%
  mutate(ScenicQuality = factor(VS_46, levels = c("Low", "Moderate", "High", "Outstanding")),
             Integrity = factor(VS_47, levels = c("Low", "Moderate", "High", "Outstanding")),
             Character = factor(VS_48, levels = c("Low", "Moderate", "High", "Outstanding")),
                Rarity = factor(VS_49, levels = c("Low", "Moderate", "High", "Outstanding"))) %>%
  dplyr::select(ScenicQuality, Integrity, Character, Rarity) %>%
  fasterize(raster(extent(.), resolution = 50, crs = 27700),
            field = "ScenicQuality")

# have a look
plot(VS)  

hex.5km$SQ <- raster::extract(VS, as(hex.5km, "Spatial"), na.rm = FALSE, df = FALSE, factors = TRUE) %>%
  rapply(function(x) which.max(tabulate(x)), how = "replace") %>%
  lapply(function(x) ifelse(is.null(x), NA, x)) %>%
  unlist() %>%
  factor(levels = c(1, 2, 3, 4)) %>%
  plyr::mapvalues(from = c(1, 2, 3, 4), to = c("Low", "Moderate", "High", "Outstanding"))

hex.2km$SQ <- raster::extract(VS, as(hex.2km, "Spatial"), na.rm = FALSE, df = FALSE, factors = TRUE) %>%
  rapply(function(x) which.max(tabulate(x)), how = "replace") %>%
  lapply(function(x) ifelse(is.null(x), NA, x)) %>%
  unlist() %>%
  factor(levels = c(1, 2, 3, 4)) %>%
  plyr::mapvalues(from = c(1, 2, 3, 4), to = c("Low", "Moderate", "High", "Outstanding"))
```

# Exploratory analysis (using Pirate plot)

```{r}
# Set margins of document for our new custom figure
par(mfrow = c(1, 1), mar = c(4,4.5,2,2))

# Create a custom pirate plot! (yar!)
bespoke_plot <- function(observation, formula, title, x.label, y.label){
  pirateplot(formula = formula,
             data = observation,
             pal = c("#EA4335", "#FBBC05","#34A853","#4285F4"),
             xlab = x.label,
             ylab = y.label,
             main = title,
             theme = 0, # set theme to 0
             bean.f.o = .4, # Bean fill
             point.o = .4, # Points
             inf.f.o = .4, # Inference fill
             inf.b.o = .8, # Inference border
             avg.line.o = 0.8, # Average line
             point.cex = .2, # Points
             quant = c(.1, .9)) #, # Adjust quantiles
             #ylim = c(0, 5))  # Adjust y axis limits
  text(x = c(1, 2, 3, 4), 
       y = 1 , 
       labels = paste(summary(observation$SQ)[1:4]), 
       cex = 1) #print number of rows of data
}

p1 <- bespoke_plot(observation = hex.5km, 
                   formula = Sce ~ SQ,
                   title = "Relationship between Scenic Quality and Scenicness",
                   x.label = "LANDMAP evaluation of scenc quality",
                   y.label = "Scenic-Or-Not ratings")
p2 <- bespoke_plot(observation = hex.2km, 
                   formula = Sce ~ SQ,
                   title = "Relationship between Scenic Quality and Scenicness",
                   x.label = "LANDMAP evaluation of scenc quality",
                   y.label = "Scenic-Or-Not ratings")

p3 <- bespoke_plot(observation = hex.5km, 
                   formula = Abs ~ SQ,
                   title = "Relationship between Scenic Quality and Absence",
                   x.label = "LANDMAP evaluation of scenc quality",
                   y.label = "Absence of human artefacts")
p4 <- bespoke_plot(observation = hex.2km, 
                   formula = Abs ~ SQ,
                   title = "Relationship between Scenic Quality and Absence",
                   x.label = "LANDMAP evaluation of scenc quality",
                   y.label = "Absence of human artefacts")

p5 <- bespoke_plot(observation = hex.5km, 
                   formula = Nat ~ SQ,
                   title = "Relationship between Scenic Quality and Naturalness",
                   x.label = "LANDMAP evaluation of scenc quality",
                   y.label = "Naturalness of perceived land cover")
p6 <- bespoke_plot(observation = hex.2km, 
                   formula = Nat ~ SQ,
                   title = "Relationship between Scenic Quality and Naturalness",
                   x.label = "LANDMAP evaluation of scenc quality",
                   y.label = "Naturalness of perceived land cover")

p7 <- bespoke_plot(observation = hex.5km, 
                   formula = Rem ~ SQ,
                   title = "Relationship between Scenic Quality and Remoteness",
                   x.label = "LANDMAP evaluation of scenc quality",
                   y.label = "Remoteness from mechanised roads")
p8 <- bespoke_plot(observation = hex.2km, 
                   formula = Rem ~ SQ,
                   title = "Relationship between Scenic Quality and Remoteness",
                   x.label = "LANDMAP evaluation of scenc quality",
                   y.label = "Remoteness from mechanised roads")

p9 <- bespoke_plot(observation = hex.5km, 
                   formula = Rug ~ SQ,
                   title = "Relationship between Scenic Quality and Ruggedness",
                   x.label = "LANDMAP evaluation of scenc quality",
                   y.label = "Ruggedness of terrain")
p10 <- bespoke_plot(observation = hex.2km, 
                   formula = Rug ~ SQ,
                   title = "Relationship between Scenic Quality and Ruggedness",
                   x.label = "LANDMAP evaluation of scenc quality",
                   y.label = "Ruggedness of terrain")
```

# Ordinal regression

# 

```{r}
##### 3.2. Include wildness components as additional predictors
model1 = polr(SQ ~ scale(Sce), data = as(hex.5km, "Spatial"), Hess = TRUE)
model2 = polr(SQ ~ scale(Sce) + scale(Abs), data = as(hex.5km, "Spatial"), Hess = TRUE)
model3 = polr(SQ ~ scale(Sce) + scale(Abs) + scale(Nat), data = as(hex.5km, "Spatial"), Hess = TRUE)
model4 = polr(SQ ~ scale(Sce) + scale(Abs) + scale(Nat) + scale(Rem), as(hex.5km, "Spatial"), Hess = TRUE)
model5 = polr(SQ ~ scale(Sce) + scale(Abs) + scale(Nat) + scale(Rem) + scale(Rug), as(hex.5km, "Spatial"), Hess = TRUE)
model6 = polr(SQ ~ scale(Sce) + scale(Abs) + scale(Nat) + scale(Rug), as(hex.5km, "Spatial"), Hess = TRUE)

summary(model1)
summary(model2)
summary(model3)
summary(model4)
summary(model5)
summary(model6)

AIC.scores <- c(AIC(model1), AIC(model2), AIC(model3), AIC(model4), AIC(model5), AIC(model6))
names(AIC.scores) <- c("model1", "model2", "model3", "model4", "model5", "model6")
AICw <- geiger::aicw(AIC.scores)

table <- function(model){
  summary_table <- coef(model) %>% exp() %>% round(3) %>% as.data.frame() 
  pval <- 
    coef(summary(model))[1:length(model$coefficients), "t value"] %>% 
    abs() %>%
    pnorm(., lower.tail = FALSE)*2 
  tab <- cbind("Odds Ratio" = summary_table, "p value" = round(pval, 3))
  return(tab)
}

table(model1)
table(model2)
table(model3)
table(model4)
table(model5)
table(model6)
```

```{r}
##### 3.2. Include wildness components as additional predictors
model1 = polr(SQ ~ scale(Sce), data = as(hex.2km, "Spatial"), Hess = TRUE)
model2 = polr(SQ ~ scale(Sce) + scale(Abs), data = as(hex.2km, "Spatial"), Hess = TRUE)
model3 = polr(SQ ~ scale(Sce) + scale(Abs) + scale(Nat), data = as(hex.2km, "Spatial"), Hess = TRUE)
model4 = polr(SQ ~ scale(Sce) + scale(Abs) + scale(Nat) + scale(Rem), as(hex.2km, "Spatial"), Hess = TRUE)
model5 = polr(SQ ~ scale(Sce) + scale(Abs) + scale(Nat) + scale(Rem) + scale(Rug), as(hex.2km, "Spatial"), Hess = TRUE)
model6 = polr(SQ ~ scale(Sce) + scale(Abs) + scale(Nat) + scale(Rug), as(hex.2km, "Spatial"), Hess = TRUE)

summary(model1)
summary(model2)
summary(model3)
summary(model4)
summary(model5)
summary(model6)

AIC.scores <- c(AIC(model1), AIC(model2), AIC(model3), AIC(model4), AIC(model5), AIC(model6))
names(AIC.scores) <- c("model1", "model2", "model3", "model4", "model5", "model6")
AICw <- geiger::aicw(AIC.scores)

table <- function(model){
  summary_table <- coef(model) %>% exp() %>% round(3) %>% as.data.frame() 
  pval <- 
    coef(summary(model))[1:length(model$coefficients), "t value"] %>% 
    abs() %>%
    pnorm(., lower.tail = FALSE)*2 
  tab <- cbind("Odds Ratio" = summary_table, "p value" = round(pval, 3))
  return(tab)
}

table(model1)
table(model2)
table(model3)
table(model4)
table(model5)
table(model6)
```

# GLM

```{r}
##### 3.1. Global Model: Generalised Linear Model
# hex.5km %>%
#   drop_na() %>%
#   as("Spatial") %>%
#   glm(SQ ~ scale(Sce) + scale(Abs) + scale(Nat) + scale(Rem) + scale(Rug),
#       data = .,
#       family = "poisson") %>%
#   summary()
# 
# R2 = 1 - glm$deviance/glm$null.deviance
```

# Machine learning - Gradient Boosted

```{r}
# GBM hyper-parameters tuning
# From kaggle: https://www.sciencedirect.com/science/article/pii/S0378778817320844
##### Split data into training and validation dataset
set.seed(2046)
TrainIndex <- hex.2km %>% drop_na() %>% .$SQ %>% createDataPartition(p = .8, list = FALSE, times = 1)
Train <- hex.2km[TrainIndex, ]
Test  <- hex.2km[-TrainIndex, ]

nrounds = 1000
tune_grid <- expand.grid(
  nrounds = seq(from = 100, to = nrounds, by = 100),
  eta = c(0.05, 0.01, 0.005, 0.001),
  max_depth = 5,
  colsample_bytree = 1, # percent of columns to sample from for each tree
  min_child_weight = 1, # minimum node size
  subsample = 0.5,      # percent of training data to sample for each tree
  #gamma = 0
  gamma = 1
  # lambda = c(0, 1e-2, 0.1, 1, 100, 1000, 10000),
  # alpha = c(0, 1e-2, 0.1, 1, 100, 1000, 10000)
)

tune_control <- caret::trainControl(
  method = "cv", # cross-validation
  #method = "repeatedcv",
  #repeats = 2,
  number = 20, # with n folds 
  #index = createFolds(tr_treated$Id_clean), # fix the folds
  verboseIter = FALSE, # no training log
  allowParallel = FALSE, # FALSE for reproducible results
  returnData = FALSE,
  #classProbs = TRUE,
  #summaryFunction = multiClassSummary
  #summaryFunction = twoClassSummary
)

train_time <- system.time({
  xgb_tune <- caret::train(
    x = Train %>% dplyr::select(Sce, Abs, Nat, Rem, Rug) %>% st_drop_geometry() %>% as.matrix() %>% xgb.DMatrix(),
    y = Train$SQ,
    trControl = tune_control,
    tuneGrid = tune_grid,
    metric = "Accuracy",
    method = "xgbTree",
    # selectionFunction = "best", "oneSE","tolerance",
    # objective = "multi:softprob",
    # eval_metric = "mlogloss",
    num_class = 4
    )
  })
xgb_tune$bestTune
max(xgb_tune$results$Accuracy)

# helper function for the plots
tuneplot <- function(x) {
  ggplot(x) +
    coord_cartesian(ylim = c(max(x$results$Accuracy), min(x$results$Accuracy))) +
    theme_bw()
}

tuneplot(xgb_tune)

# Reference
# https://github.com/topepo/caret/issues/389
```

```{r}
# Model evaluation
#predicted = predict(xgb_tune, x_test)
# Predict outcomes with the test data
Test %>% dplyr::select(Sce, Abs, Nat, Rem, Rug) %>%
  st_drop_geometry() %>% 
  as.matrix() %>% 
  xgb.DMatrix() %>%
  predict(xgb_tune, ., reshape = T) %>%
  plyr::mapvalues(from = c(1, 2, 3, 4), to = c("Low", "Moderate", "High", "Outstanding")) %>%
  data.frame(predict = .) %>%
  data.frame(actual = plyr::mapvalues(Test$SQ, from = c(1, 2, 3, 4), to = c("Low", "Moderate", "High", "Outstanding")),
             predict = .) ->
  result

# confusion matrix
confusionMatrix(result$actual, result$predict) %>% print()

# Reference
# https://datascienceplus.com/extreme-gradient-boosting-with-r/

hex.2k$SQ.pred <-
  hex.2k %>%
  st_drop_geometry() %>%
  dplyr::select(Sce, Abs, Nat, Rem, Rug) %>%
  predict(xgb_tune, ., reshape = T) %>%
  plyr::mapvalues(from = c(1, 2, 3, 4), to = c("Low", "Moderate", "High", "Outstanding")) %>%
  as.factor()
```

# Visualisation

```{r}
theme_map <- function(...) {
  theme_minimal() +
    theme(
      text = element_text(family = "Arial", color = "#22211d"), #"Ubuntu Regular"
      axis.line = element_blank(),
      axis.text.x = element_blank(),
      axis.text.y = element_blank(),
      axis.ticks = element_blank(),
      axis.title.x = element_blank(),
      axis.title.y = element_blank(),
      # panel.grid.minor = element_line(color = "#ebebe5", size = 0.2),
      panel.grid.major = element_blank(), #element_line(color = "#ebebe5", size = 0.2),
      panel.grid.minor = element_blank(),
      plot.background = element_blank(), #element_rect(fill = "#f5f5f2", color = NA), 
      panel.background = element_blank(), #element_rect(fill = "#f5f5f2", color = NA), 
      legend.background = element_blank(), #element_rect(fill = "#f5f5f2", color = NA),
      panel.border = element_blank(),
      ...
    )
}

p <- ggplot(hex.2k) +
  # municipality polygons
  geom_sf(aes(fill = SQ.pred), color = NA) +
  theme_map() +
  labs(x = NULL, y = NULL, 
       title = "Predicted scenic quality") +
  theme(legend.position = "bottom",
        title =element_text(size = 15)) +
  scale_fill_manual(
  # in manual scales, one has to define colors, well, manually
  # I can directly access them using viridis' magma-function
  values = RColorBrewer::brewer.pal(4, "YlOrBr"), #rev(magma(9)),
  #breaks = brks_scale,
  name = "Quality levels",
  drop = FALSE,
  labels = c("Low", "Moderate", "High", "Outstanding"),
  guide = guide_legend(
    direction = "horizontal",
    keyheight = unit(6, units = "mm"),
    keywidth = unit(30 / length(labels), units = "mm"),
    title.position = 'top',
    title.theme = element_text(size = 15),
    # I shift the labels around, the should be placed 
    # exactly at the right end of each legend key
    # title.hjust = -0.9,
    label.hjust = 0.2,
    label.theme = element_text(size = 12),
    nrow = 1,
    byrow = T,
    # also the guide needs to be reversed
    reverse = F,
    label.position = "bottom")
  )


plot(test[, "SQ"])
```
